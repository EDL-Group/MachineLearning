{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## EXAMPLE OF DATA PRE-PROCESSING\n",
    "The Diabetes Dataset involves predicting the onset of diabetes within 5 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We would need these libraries to manage our dataset\n",
    "# Numpy: used for large, multi-dimensional arrays and matrices, and for high-level mathematical functions\n",
    "# Pandas: used for data manipulation and analysis\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This line will allow us to load the dataset\n",
    "The dataset should be in a CSV format\n",
    "A CSV file is a delimited text file that uses a comma to separate values. \n",
    "Each line of the file is a data record.\n",
    "''' \n",
    "# header: indicates if the dataset has an initial line with the name of each column\n",
    "dataset = pd.read_csv('pima-indians-diabetes.csv', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attributes of the dataset: (all numeric-valued with no header)\n",
    "   1. Number of times pregnant\n",
    "   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "   3. Diastolic blood pressure (mm Hg)\n",
    "   4. Triceps skin fold thickness (mm)\n",
    "   5. 2-Hour serum insulin (mu U/ml)\n",
    "   6. Body mass index (weight in kg/(height in m)^2)\n",
    "   7. Diabetes pedigree function\n",
    "   8. Age (years)\n",
    "   9. Class variable (0 or 1)\n",
    "where class value 1 is interpreted as \"tested positive for diabetes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1   2   3    4     5      6   7  8\n",
       "0  6  148  72  35    0  33.6  0.627  50  1\n",
       "1  1   85  66  29    0  26.6  0.351  31  0\n",
       "2  8  183  64   0    0  23.3  0.672  32  1\n",
       "3  1   89  66  23   94  28.1  0.167  21  0\n",
       "4  0  137  40  35  168  43.1  2.288  33  1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Head visualise the five first rows of your dataset\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                0           1           2           3           4           5  \\\n",
      "count  768.000000  768.000000  768.000000  768.000000  768.000000  768.000000   \n",
      "mean     3.845052  120.894531   69.105469   20.536458   79.799479   31.992578   \n",
      "std      3.369578   31.972618   19.355807   15.952218  115.244002    7.884160   \n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%      1.000000   99.000000   62.000000    0.000000    0.000000   27.300000   \n",
      "50%      3.000000  117.000000   72.000000   23.000000   30.500000   32.000000   \n",
      "75%      6.000000  140.250000   80.000000   32.000000  127.250000   36.600000   \n",
      "max     17.000000  199.000000  122.000000   99.000000  846.000000   67.100000   \n",
      "\n",
      "                6           7           8  \n",
      "count  768.000000  768.000000  768.000000  \n",
      "mean     0.471876   33.240885    0.348958  \n",
      "std      0.331329   11.760232    0.476951  \n",
      "min      0.078000   21.000000    0.000000  \n",
      "25%      0.243750   24.000000    0.000000  \n",
      "50%      0.372500   29.000000    0.000000  \n",
      "75%      0.626250   41.000000    1.000000  \n",
      "max      2.420000   81.000000    1.000000  \n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "First, we will try to 'visualise' the dataset\n",
    "'''\n",
    "# describe shows us a nice summary of descriptive statistics for each of the columns\n",
    "print(dataset.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that columns are shown from zero to N-1\n",
    "* Count: gives us the number of rows in the dataset\n",
    "* Mean: mean of all the values in each column\n",
    "* std: standard deviation\n",
    "* min, max: minimum and maximum values\n",
    "* 25%, 50%, and 75%: the 25th, 50th, and 75th percentiles, which is the same than quantile 1, quantile 2, and quantile 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "There are missing observations for some columns that are marked as a zero value.\n",
    "Note that this does not include column 8, the class variable where zero indicates that the subject is not tested positive\n",
    "Note that the minimum value in column 6 and 7 is different than zero, then there is no missing values in these columns\n",
    "'''\n",
    "# replace: allow us to replace a given value with another one\n",
    "# In this case, we want to replace '0' values with 'nan'\n",
    "# In Pandas missing data is represented by the None object and nan (not a number)\n",
    "# Pandas treat None and NaN as essentially interchangeable for indicating missing or null values. \n",
    "dataset[[1,2,3,4,5]] = dataset[[1,2,3,4,5]].replace(0, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0\n",
      "1      5\n",
      "2     35\n",
      "3    227\n",
      "4    374\n",
      "5     11\n",
      "6      0\n",
      "7      0\n",
      "8      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "We are going to count the number of NAN values in each column\n",
    "'''\n",
    "# isnull returns all the nan instances \n",
    "# sum sums all the previous nan occurrences\n",
    "print(dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that the number of null instances varies significantly.\n",
    "We are going to calculate the percentage of them to see the real inpact\n",
    "\n",
    "The formula is:\n",
    "\n",
    "$\\Large\\frac{NumberNullValues}{TotalNumberSamples}*100$\n",
    "\n",
    "We need to calculate the total number of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=768, step=1)\n"
     ]
    }
   ],
   "source": [
    "# The index of the dataset give us the range of values\n",
    "print(dataset.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n"
     ]
    }
   ],
   "source": [
    "# The length of the index returns the total number of samples\n",
    "print(len(dataset.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     0.000000\n",
      "1     0.651042\n",
      "2     4.557292\n",
      "3    29.557292\n",
      "4    48.697917\n",
      "5     1.432292\n",
      "6     0.000000\n",
      "7     0.000000\n",
      "8     0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Now we are going to calculate the percentage of values that are null for each column\n",
    "The treatment of these null values may be different according to their quantity\n",
    "'''\n",
    "values = dataset.isnull().sum()/len(dataset.index)*100\n",
    "print(values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0%\n",
      "1%\n",
      "5%\n",
      "30%\n",
      "49%\n",
      "1%\n",
      "0%\n",
      "0%\n",
      "0%\n"
     ]
    }
   ],
   "source": [
    "# We can also format the output to give us the %\n",
    "# for that we need to iterate through the vector\n",
    "for i in values:\n",
    " print(\"%.0f%%\" % (i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove rows with missing values\n",
    "The simplest approach for dealing with missing values is to remove the entire sample that contain missing values.\n",
    "Pandas provides the **dropna()** function that can be used to drop either columns or rows with missing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    }
   ],
   "source": [
    "# We can show the dimensions of the dataset before the removal with the function shape\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "We can use it to remove all rows with missing data, as follows:\n",
    "'''\n",
    "# inplace=False returns a copy of the object with the operation performed. inplace=True returns None\n",
    "dataset.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(392, 9)\n"
     ]
    }
   ],
   "source": [
    "# summarize the shape of the data with missing rows removed\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that we get rid of the problem, but removing almost half of our dataset, worthy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filled in missing values\n",
    "There are many options we could consider when replacing a missing value, for example:\n",
    "* A constant value that has meaning within the domain, such as 0, distinct from all other values. \n",
    "* A value from another randomly selected record. \n",
    "* A mean, median or mode value for the column. \n",
    "* A value estimated by another predictive model. \n",
    "\n",
    "Pandas provides the **fillna()** function for replacing missing values with a specific value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Again we load the dataset and mark missing values to have a fresh data\n",
    "'''\n",
    "# load again the dataset\n",
    "dataset = pd.read_csv('pima-indians-diabetes.csv', header=None)\n",
    "# mark zero values as missing or NaN\n",
    "dataset[[1,2,3,4,5]] = dataset[[1,2,3,4,5]].replace(0, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0\n",
      "1      5\n",
      "2     35\n",
      "3    227\n",
      "4    374\n",
      "5     11\n",
      "6      0\n",
      "7      0\n",
      "8      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# count again the number of NaN values in each column\n",
    "print(dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing values with mean column values\n",
    "dataset.fillna(dataset.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "5    0\n",
      "6    0\n",
      "7    0\n",
      "8    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# count again the number of NaN values in each column\n",
    "print(dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalisation of the data\n",
    "We are going to use mix-max normalisation to scale the features of our dataset.\n",
    "This method rescales the range of the data to [0,1]\n",
    "The formula is the following:\n",
    "\n",
    "$\\Large x_n=\\frac{x-min(x)}{max(x)-min(x)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                0           1           2           3           4           5  \\\n",
      "count  768.000000  768.000000  768.000000  768.000000  768.000000  768.000000   \n",
      "mean     3.845052  121.686763   72.405184   29.153420  155.548223   32.457464   \n",
      "std      3.369578   30.435949   12.096346    8.790942   85.021108    6.875151   \n",
      "min      0.000000   44.000000   24.000000    7.000000   14.000000   18.200000   \n",
      "25%      1.000000   99.750000   64.000000   25.000000  121.500000   27.500000   \n",
      "50%      3.000000  117.000000   72.202592   29.153420  155.548223   32.400000   \n",
      "75%      6.000000  140.250000   80.000000   32.000000  155.548223   36.600000   \n",
      "max     17.000000  199.000000  122.000000   99.000000  846.000000   67.100000   \n",
      "\n",
      "                6           7           8  \n",
      "count  768.000000  768.000000  768.000000  \n",
      "mean     0.471876   33.240885    0.348958  \n",
      "std      0.331329   11.760232    0.476951  \n",
      "min      0.078000   21.000000    0.000000  \n",
      "25%      0.243750   24.000000    0.000000  \n",
      "50%      0.372500   29.000000    0.000000  \n",
      "75%      0.626250   41.000000    1.000000  \n",
      "max      2.420000   81.000000    1.000000  \n"
     ]
    }
   ],
   "source": [
    "# we use again describe to show the summary of descriptive statistics for each of the columns\n",
    "print(dataset.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     17.00\n",
      "1    199.00\n",
      "2    122.00\n",
      "3     99.00\n",
      "4    846.00\n",
      "5     67.10\n",
      "6      2.42\n",
      "7     81.00\n",
      "8      1.00\n",
      "dtype: float64\n",
      "0     0.000\n",
      "1    44.000\n",
      "2    24.000\n",
      "3     7.000\n",
      "4    14.000\n",
      "5    18.200\n",
      "6     0.078\n",
      "7    21.000\n",
      "8     0.000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# We see that we need to calculate the maximum and minimum values for each attibute\n",
    "# This is done with functions min() and max()\n",
    "column_max = dataset.max()\n",
    "column_min = dataset.min()\n",
    "print(column_max)\n",
    "print(column_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and now we calculate the formula\n",
    "dataset_norm = (dataset - column_min) / (column_max - column_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                0           1           2           3           4           5  \\\n",
      "count  768.000000  768.000000  768.000000  768.000000  768.000000  768.000000   \n",
      "mean     0.226180    0.501205    0.493930    0.240798    0.170130    0.291564   \n",
      "std      0.198210    0.196361    0.123432    0.095554    0.102189    0.140596   \n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%      0.058824    0.359677    0.408163    0.195652    0.129207    0.190184   \n",
      "50%      0.176471    0.470968    0.491863    0.240798    0.170130    0.290389   \n",
      "75%      0.352941    0.620968    0.571429    0.271739    0.170130    0.376278   \n",
      "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
      "\n",
      "                6           7           8  \n",
      "count  768.000000  768.000000  768.000000  \n",
      "mean     0.168179    0.204015    0.348958  \n",
      "std      0.141473    0.196004    0.476951  \n",
      "min      0.000000    0.000000    0.000000  \n",
      "25%      0.070773    0.050000    0.000000  \n",
      "50%      0.125747    0.133333    0.000000  \n",
      "75%      0.234095    0.333333    1.000000  \n",
      "max      1.000000    1.000000    1.000000  \n"
     ]
    }
   ],
   "source": [
    "# we use again describe to show the summary of descriptive statistics for each of the columns\n",
    "print(dataset_norm.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
